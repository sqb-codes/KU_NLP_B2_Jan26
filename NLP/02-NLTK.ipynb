{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5624754-543c-4577-90a7-1589869fd40f",
   "metadata": {},
   "source": [
    "# NLTK - Natural Language ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf0e974-164b-41ed-a3dc-3334d014f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# 4 things to do with NLTK\n",
    "# a. Tokenization\n",
    "# b. Stopword Removal\n",
    "# c. Stemming\n",
    "# d. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7456cb9-b8a3-4379-be8c-8d760b6d54b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ravikanttyagi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ravikanttyagi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ravikanttyagi/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105b47b2-9cd3-4685-8325-40e7c32835b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/ravikanttyagi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7863952b-d745-40e7-a6bf-74d202762eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Stopwords list\n",
    "from nltk.corpus import stopwords\n",
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca60956f-2f1b-4264-b1d6-ad2ad642812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"I am learning Python programming, Python is greatest language..!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c184ed0-1198-45ca-ab76-88df6fd36258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After lowercase:  i am learning python programming, python is greatest language..!!\n"
     ]
    }
   ],
   "source": [
    "# Step-1 : Lowercase\n",
    "raw_text = raw_text.lower()\n",
    "print(\"After lowercase: \",raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6072eca7-6b6f-4c1b-98b1-a9448ec47b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'learning', 'python', 'programming,', 'python', 'is', 'greatest', 'language..!!']\n"
     ]
    }
   ],
   "source": [
    "# Step-2 : Tokenization\n",
    "print(raw_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f700a7f0-0dc0-48be-83e4-8d8085ef1c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['i', 'am', 'learning', 'python', 'programming', ',', 'python', 'is', 'greatest', 'language', '..', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(raw_text)\n",
    "print(\"Tokens:\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "232cd8b9-1eec-45b9-97df-2eebab91a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-3 : Remove stopwords\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5297d6d9-6b93-4919-8c69-2048fdc19721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Tokens : ['learning', 'python', 'programming', ',', 'python', 'greatest', 'language', '..', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = []\n",
    "for word in tokens:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_tokens.append(word)\n",
    "\n",
    "print(\"Filtered Tokens :\",filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffabc75a-8e9b-48c1-b198-14771469184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuations Available: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Step-4 : Remove Punctuations\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "print(\"Punctuations Available:\", punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c3347c5-dc55-4acc-beee-51cec087b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing punctuations: ['learning', 'python', 'programming', 'python', 'greatest', 'language', '..']\n"
     ]
    }
   ],
   "source": [
    "clean_tokens = [word for word in filtered_tokens if word not in punctuations]\n",
    "print(\"After removing punctuations:\",clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00c0aefd-e25d-4477-97de-5d7dc9a2fff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem = PorterStemmer()\n",
    "# stem.stem(\"playing\")\n",
    "# stem.stem(\"watching\")\n",
    "# stem.stem(\"played\")\n",
    "# stem.stem(\"flying\")\n",
    "stem.stem(\"bought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d041dc5-1d01-4d68-85fe-e19699b15af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnet = WordNetLemmatizer()\n",
    "# wnet.lemmatize(\"playing\", \"v\")\n",
    "# wnet.lemmatize(\"flying\", \"v\")\n",
    "# wnet.lemmatize(\"bought\", \"v\")\n",
    "wnet.lemmatize(\"went\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de1db0f5-3553-4e78-8219-637a89b0596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Lemmatization : ['learn', 'python', 'program', 'python', 'greatest', 'language', '..']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_words = []\n",
    "for word in clean_tokens:\n",
    "    lemmatized_words.append(wnet.lemmatize(word,\"v\"))\n",
    "\n",
    "print(\"After Lemmatization :\",lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a30436f3-a831-4cab-9389-935e8d69665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tokens: ['learn', 'python', 'program', 'python', 'greatest', 'language']\n"
     ]
    }
   ],
   "source": [
    "final_tokens = []\n",
    "for word in lemmatized_words:\n",
    "    if word.isalpha():\n",
    "        final_tokens.append(word)\n",
    "\n",
    "print(\"Final Tokens:\",final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd709454-bc3f-4829-ac53-e8e26f261002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: learn python program python greatest language\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = \" \".join(final_tokens)\n",
    "print(\"Cleaned Text:\",cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32751f28-ef8e-4586-befc-b43f276fa565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
