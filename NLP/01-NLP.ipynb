{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8787fa4-4f80-4347-99d4-183473614100",
   "metadata": {},
   "source": [
    "# NLP Phase-1: Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935173f8-e0fe-48f5-808d-62dacd60bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text processing pipeline\n",
    "# Text -> Cleaning -> Tokenization -> Stopwords Removal -> Stemming/Lemmetization -> Vectorization -> ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115f9844-7c33-4abf-90f4-c86e1fd3a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text : i am learning Python programming and python is fast!!..\n"
     ]
    }
   ],
   "source": [
    "text = \"i am learning Python programming and python is fast!!..\"\n",
    "print(\"Original text :\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921fea9d-a18d-4b73-aa59-e258857d9902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase : i am learning python programming and python is fast!!..\n"
     ]
    }
   ],
   "source": [
    "# Step-1: Convert to lowercase\n",
    "text = text.lower()\n",
    "# Python != python\n",
    "print(\"Lowercase :\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92451848-2d1c-419d-a3d0-8fff4dd7db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without punctuation: i am learning python programming and python is fast\n"
     ]
    }
   ],
   "source": [
    "# Step-2: Remove Punctuation - !@#$%^&*()_;'.,\n",
    "# re - regex - regular expression\n",
    "import re\n",
    "\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "# remove everythin except letters and spaces\n",
    "print(\"Without punctuation:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bbbb72-3ce6-4ae8-9f48-c9e9dca97d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens : ['i', 'am', 'learning', 'python', 'programming', 'and', 'python', 'is', 'fast']\n"
     ]
    }
   ],
   "source": [
    "# Step-3: Tokenization (Split sentence into words)\n",
    "tokens = text.split()\n",
    "print(\"Tokens :\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f36544a-66cd-4330-a7e4-309249db75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing stopwords: ['learning', 'python', 'programming', 'python', 'fast']\n"
     ]
    }
   ],
   "source": [
    "# Step-4: Remove Stopwords - is, am, are, the, a an\n",
    "stopwords = [\"a\",\"am\",\"is\",\"i\",\"the\",\"and\"]\n",
    "filtered_tokens = []\n",
    "\n",
    "for word in tokens:\n",
    "    if word not in stopwords:\n",
    "        filtered_tokens.append(word)\n",
    "\n",
    "print(\"After removing stopwords:\",filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cb52dd7-b511-4078-ba1a-58d6e23ff113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stemming : ['learn', 'python', 'programm', 'python', 'fast']\n"
     ]
    }
   ],
   "source": [
    "def stem(word):\n",
    "    if word.endswith(\"ing\"):\n",
    "        return word[:-3]\n",
    "    return word\n",
    "\n",
    "stemmed_words = []\n",
    "for word in filtered_tokens:\n",
    "    stemmed_words.append(stem(word))\n",
    "\n",
    "print(\"After stemming :\",stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0371f-bf28-4604-93f8-e756dd4f31d5",
   "metadata": {},
   "source": [
    "# NLP Phase-2: Word to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523ba812-34e0-4818-baf6-832d389eab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why Vectors ?\n",
    "# ML models only understand numbers\n",
    "\n",
    "# Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6414b3f9-0494-49f7-9a35-65c151e4ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will convert text -> count\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "583cd6a1-cdc1-4e2b-b8ff-4078350e9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"i am learning python and python\",\n",
    "    \"we are happy today\",\n",
    "    \"i am sad today\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cde43beb-b1c6-4bca-9773-d408605fa6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()  # create object\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "# learns vocabulary\n",
    "# convert sentences to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8999769-1430-4ef4-a74e-fd6a835ac853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary : ['am' 'and' 'are' 'happy' 'learning' 'python' 'sad' 'today' 'we']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary :\",vectorizer.get_feature_names_out())\n",
    "# 1. all unique words\n",
    "# 2. sorted in albhabetical order\n",
    "# 3. remove single letters like i, a, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82c3587a-a367-41c6-8e19-30db00b39fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors:\n",
      "[[1 1 0 0 1 2 0 0 0]\n",
      " [0 0 1 1 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectors:\")\n",
    "print(X.toarray())\n",
    "# Each row is a sentence\n",
    "# Each column is a word\n",
    "# Each value is a count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a0f28-925a-4128-a41f-a5c38231b993",
   "metadata": {},
   "source": [
    "# TF-IDF = Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9e32294-f091-43ef-8237-189480157969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why TF-IDF ?\n",
    "# Because count is not enough\n",
    "# Bag of words treats all words equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfe33c94-1ca8-402d-8132-b1997e95685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5f097b-05ed-4761-b90a-61b292ba3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"i am learning python and python\",\n",
    "    \"we are happy today\",\n",
    "    \"i am sad today\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c33910-d2b9-4422-b939-c6023a2a4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "# build vocabulary\n",
    "# calculate TF\n",
    "# calculate idf - impact of each word\n",
    "# multiples - tf x idf\n",
    "# produces matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b54d72b-97cc-47a5-ad14-2edfbfdaa346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary : ['am' 'and' 'are' 'happy' 'learning' 'python' 'sad' 'today' 'we']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary :\",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a9ee138-6834-44eb-b01d-c0864b7a9697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix :\n",
      "[[0.29651988 0.38988801 0.         0.         0.38988801 0.77977602\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.52863461 0.52863461 0.         0.\n",
      "  0.         0.40204024 0.52863461]\n",
      " [0.51785612 0.         0.         0.         0.         0.\n",
      "  0.68091856 0.51785612 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Matrix :\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7deaf913-e1af-4267-bbf0-2401190354df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count + Impact of each word\n",
    "# TF-IDF rewards rare important words and penalizes common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c05e037f-56a9-462d-8ff6-6d3da4baacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF = count(words) / total_words\n",
    "# IDF = log(total_docs / documents_containing_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11ce5d-36ce-4e85-a56a-fcde5730d8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
